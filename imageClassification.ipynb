{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Convolutional Neural Network\n",
    "\n",
    "# Installing Theano\n",
    "# pip install --upgrade --no-deps git+git://github.com/Theano/Theano.git\n",
    "\n",
    "# Installing Tensorflow\n",
    "# pip install tensorflow\n",
    "\n",
    "# Installing Keras\n",
    "# pip install --upgrade keras\n",
    "\n",
    "# Part 1 - Building the CNN\n",
    "\n",
    "# Importing the Keras libraries and packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/dev2/Sanjana/venv/lib64/python3.6/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/dev2/Sanjana/venv/lib64/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/dev2/Sanjana/venv/lib64/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/dev2/Sanjana/venv/lib64/python3.6/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Initialising the CNN\n",
    "classifier = Sequential()\n",
    "\n",
    "# Step 1 - Convolution\n",
    "# Convolution - input image, applying feature detectors => feature map\n",
    "# 3D Array because colored images\n",
    "classifier.add(Conv2D(32, (3, 3), input_shape = (64, 64, 3), activation = 'relu'))\n",
    "\n",
    "# Step 2 - Pooling\n",
    "# Feature Map - Take Max -> Pooled Feature Map, reduced size, reduce complexity\n",
    "# without losing performance, don't lose spatial structure\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "# Adding second convolution layer\n",
    "# don't need to include input_shape since we're done it\n",
    "classifier.add(Conv2D(32, (3, 3), activation = 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/dev2/Sanjana/venv/lib64/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/dev2/Sanjana/venv/lib64/python3.6/site-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/dev2/Sanjana/venv/lib64/python3.6/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 3 - Flattening\n",
    "# Pooled Feature Maps apply flattening maps to a huge vector \n",
    "# for a future ANN that is fully-conntected\n",
    "# Why don't we lose spatial structure by flattening?\n",
    "# We don't because the high numbers from convolution feature from the feature detector\n",
    "# Max Pooling keeps them these high numbers, and flattening keeps these high numbers\n",
    "# Why didn't we take all the pixels and flatten into a huge vector?\n",
    "# Only pixels of itself, but not how they're spatially structured around it\n",
    "# But if we apply convolution and pooling, since feature map corresponds to each feature \n",
    "# of an image, specific image unique pixels, we keep the spatial structure of the picture.\n",
    "classifier.add(Flatten())\n",
    "\n",
    "\n",
    "# Step 4 - Full Connection\n",
    "classifier.add(Dense(units = 128, activation = 'relu'))\n",
    "classifier.add(Dense(units = 1, activation = 'sigmoid'))\n",
    "\n",
    "# Compile - SGD, Loss Function, Performance Metric\n",
    "# Logarithmic loss - binary cross entropy, more than two outcomes, categorical cross entropy\n",
    "# Metrics is the accuracy metric\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# part 2 - Fitting the CNN to the images \n",
    "# Keras preprocessing images to prevent overfitting, image augmentation, \n",
    "# great accuracy on training poor results on test sets\n",
    "# Need lots of images to find correlations, patterns in pixels\n",
    "# Find patterns in pixels, 10000 images, 8000 training, not much exactly or use a trick\n",
    "# Image augmentation will create batches and each batch will create random transformation\n",
    "# leading to more diverse images and more training\n",
    "# Image augmentation allows us to enrich our dataset to prevent overfitting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 262 images belonging to 2 classes.\n",
      "Found 10 images belonging to 2 classes.\n",
      "WARNING:tensorflow:From /home/dev2/Sanjana/venv/lib64/python3.6/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dev2/Sanjana/venv/lib64/python3.6/site-packages/ipykernel_launcher.py:25: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "/home/dev2/Sanjana/venv/lib64/python3.6/site-packages/ipykernel_launcher.py:25: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras_pre..., validation_data=<keras_pre..., steps_per_epoch=3, epochs=50, validation_steps=200)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "3/3 [==============================] - 3s 967ms/step - loss: 1.2046 - acc: 0.6979 - val_loss: 0.8282 - val_acc: 0.5000\n",
      "Epoch 2/50\n",
      "3/3 [==============================] - 1s 279ms/step - loss: 0.6761 - acc: 0.6458 - val_loss: 0.6925 - val_acc: 0.5000\n",
      "Epoch 3/50\n",
      "3/3 [==============================] - 1s 276ms/step - loss: 0.6766 - acc: 0.7274 - val_loss: 0.6908 - val_acc: 0.5000\n",
      "Epoch 4/50\n",
      "3/3 [==============================] - 1s 279ms/step - loss: 0.6269 - acc: 0.7812 - val_loss: 0.7962 - val_acc: 0.5000\n",
      "Epoch 5/50\n",
      "3/3 [==============================] - 1s 278ms/step - loss: 0.6630 - acc: 0.6458 - val_loss: 0.8470 - val_acc: 0.5000\n",
      "Epoch 6/50\n",
      "3/3 [==============================] - 1s 274ms/step - loss: 0.6591 - acc: 0.6025 - val_loss: 0.6801 - val_acc: 0.5000\n",
      "Epoch 7/50\n",
      "3/3 [==============================] - 1s 278ms/step - loss: 0.5959 - acc: 0.7292 - val_loss: 0.6753 - val_acc: 0.5000\n",
      "Epoch 8/50\n",
      "3/3 [==============================] - 1s 279ms/step - loss: 0.5784 - acc: 0.7083 - val_loss: 0.8697 - val_acc: 0.5000\n",
      "Epoch 9/50\n",
      "3/3 [==============================] - 1s 276ms/step - loss: 0.6245 - acc: 0.6249 - val_loss: 0.7109 - val_acc: 0.5000\n",
      "Epoch 10/50\n",
      "3/3 [==============================] - 1s 280ms/step - loss: 0.5314 - acc: 0.7188 - val_loss: 0.7200 - val_acc: 0.5000\n",
      "Epoch 11/50\n",
      "3/3 [==============================] - 1s 279ms/step - loss: 0.5625 - acc: 0.6667 - val_loss: 0.8786 - val_acc: 0.5000\n",
      "Epoch 12/50\n",
      "3/3 [==============================] - 1s 274ms/step - loss: 0.5166 - acc: 0.6818 - val_loss: 0.6672 - val_acc: 0.5000\n",
      "Epoch 13/50\n",
      "3/3 [==============================] - 1s 279ms/step - loss: 0.4855 - acc: 0.7188 - val_loss: 0.6402 - val_acc: 0.5000\n",
      "Epoch 14/50\n",
      "3/3 [==============================] - 1s 279ms/step - loss: 0.4479 - acc: 0.7604 - val_loss: 0.8859 - val_acc: 0.5000\n",
      "Epoch 15/50\n",
      "3/3 [==============================] - 1s 274ms/step - loss: 0.6350 - acc: 0.5794 - val_loss: 0.5022 - val_acc: 0.5000\n",
      "Epoch 16/50\n",
      "3/3 [==============================] - 1s 277ms/step - loss: 0.5553 - acc: 0.6562 - val_loss: 0.5381 - val_acc: 0.5000\n",
      "Epoch 17/50\n",
      "3/3 [==============================] - 1s 278ms/step - loss: 0.5239 - acc: 0.7708 - val_loss: 0.5586 - val_acc: 0.5000\n",
      "Epoch 18/50\n",
      "3/3 [==============================] - 1s 274ms/step - loss: 0.5293 - acc: 0.6702 - val_loss: 0.6296 - val_acc: 0.5000\n",
      "Epoch 19/50\n",
      "3/3 [==============================] - 1s 278ms/step - loss: 0.5134 - acc: 0.7292 - val_loss: 0.9666 - val_acc: 0.5000\n",
      "Epoch 20/50\n",
      "3/3 [==============================] - 1s 280ms/step - loss: 0.5207 - acc: 0.6771 - val_loss: 0.7580 - val_acc: 0.5000\n",
      "Epoch 21/50\n",
      "3/3 [==============================] - 1s 275ms/step - loss: 0.5427 - acc: 0.6252 - val_loss: 0.5224 - val_acc: 0.5000\n",
      "Epoch 22/50\n",
      "3/3 [==============================] - 1s 278ms/step - loss: 0.5048 - acc: 0.6562 - val_loss: 0.6090 - val_acc: 0.5000\n",
      "Epoch 23/50\n",
      "3/3 [==============================] - 1s 278ms/step - loss: 0.5253 - acc: 0.6875 - val_loss: 0.6693 - val_acc: 0.5000\n",
      "Epoch 24/50\n",
      "3/3 [==============================] - 1s 275ms/step - loss: 0.4757 - acc: 0.7274 - val_loss: 0.5278 - val_acc: 0.5000\n",
      "Epoch 25/50\n",
      "3/3 [==============================] - 1s 280ms/step - loss: 0.4829 - acc: 0.7083 - val_loss: 0.7005 - val_acc: 0.5000\n",
      "Epoch 26/50\n",
      "3/3 [==============================] - 1s 277ms/step - loss: 0.4951 - acc: 0.7083 - val_loss: 0.3980 - val_acc: 0.8000\n",
      "Epoch 27/50\n",
      "3/3 [==============================] - 1s 274ms/step - loss: 0.4903 - acc: 0.8065 - val_loss: 0.4283 - val_acc: 0.5000\n",
      "Epoch 28/50\n",
      "3/3 [==============================] - 1s 278ms/step - loss: 0.4686 - acc: 0.8021 - val_loss: 0.8231 - val_acc: 0.5000\n",
      "Epoch 29/50\n",
      "3/3 [==============================] - 1s 280ms/step - loss: 0.5046 - acc: 0.7396 - val_loss: 0.8234 - val_acc: 0.5000\n",
      "Epoch 30/50\n",
      "3/3 [==============================] - 1s 275ms/step - loss: 0.4701 - acc: 0.8182 - val_loss: 0.4185 - val_acc: 0.8000\n",
      "Epoch 31/50\n",
      "3/3 [==============================] - 1s 277ms/step - loss: 0.4840 - acc: 0.8333 - val_loss: 0.4057 - val_acc: 0.5000\n",
      "Epoch 32/50\n",
      "3/3 [==============================] - 1s 279ms/step - loss: 0.4328 - acc: 0.8750 - val_loss: 0.4876 - val_acc: 0.5000\n",
      "Epoch 33/50\n",
      "3/3 [==============================] - 1s 275ms/step - loss: 0.5260 - acc: 0.7385 - val_loss: 0.6913 - val_acc: 0.5000\n",
      "Epoch 34/50\n",
      "3/3 [==============================] - 1s 279ms/step - loss: 0.4845 - acc: 0.7604 - val_loss: 0.7228 - val_acc: 0.5000\n",
      "Epoch 35/50\n",
      "3/3 [==============================] - 1s 281ms/step - loss: 0.4067 - acc: 0.8125 - val_loss: 0.7708 - val_acc: 0.5000\n",
      "Epoch 36/50\n",
      "3/3 [==============================] - 1s 274ms/step - loss: 0.4669 - acc: 0.7729 - val_loss: 0.7677 - val_acc: 0.5000\n",
      "Epoch 37/50\n",
      "3/3 [==============================] - 1s 280ms/step - loss: 0.4347 - acc: 0.7917 - val_loss: 0.4965 - val_acc: 0.5000\n",
      "Epoch 38/50\n",
      "3/3 [==============================] - 1s 278ms/step - loss: 0.4274 - acc: 0.8438 - val_loss: 0.6261 - val_acc: 0.5000\n",
      "Epoch 39/50\n",
      "3/3 [==============================] - 1s 276ms/step - loss: 0.3919 - acc: 0.8406 - val_loss: 0.5208 - val_acc: 0.5000\n",
      "Epoch 40/50\n",
      "3/3 [==============================] - 1s 280ms/step - loss: 0.3733 - acc: 0.8333 - val_loss: 0.3257 - val_acc: 0.8000\n",
      "Epoch 41/50\n",
      "3/3 [==============================] - 1s 280ms/step - loss: 0.4367 - acc: 0.7500 - val_loss: 0.2792 - val_acc: 1.0000\n",
      "Epoch 42/50\n",
      "3/3 [==============================] - 1s 274ms/step - loss: 0.4515 - acc: 0.8298 - val_loss: 0.6000 - val_acc: 0.5000\n",
      "Epoch 43/50\n",
      "3/3 [==============================] - 1s 278ms/step - loss: 0.4082 - acc: 0.8750 - val_loss: 0.3046 - val_acc: 0.8000\n",
      "Epoch 44/50\n",
      "3/3 [==============================] - 1s 278ms/step - loss: 0.3487 - acc: 0.8646 - val_loss: 0.3365 - val_acc: 0.8000\n",
      "Epoch 45/50\n",
      "3/3 [==============================] - 1s 275ms/step - loss: 0.3628 - acc: 0.8298 - val_loss: 0.6907 - val_acc: 0.5000\n",
      "Epoch 46/50\n",
      "3/3 [==============================] - 1s 279ms/step - loss: 0.3535 - acc: 0.8646 - val_loss: 0.1593 - val_acc: 1.0000\n",
      "Epoch 47/50\n",
      "3/3 [==============================] - 1s 278ms/step - loss: 0.3511 - acc: 0.8438 - val_loss: 0.4778 - val_acc: 0.8000\n",
      "Epoch 48/50\n",
      "3/3 [==============================] - 1s 276ms/step - loss: 0.3520 - acc: 0.8409 - val_loss: 0.6466 - val_acc: 0.5000\n",
      "Epoch 49/50\n",
      "3/3 [==============================] - 1s 278ms/step - loss: 0.3301 - acc: 0.8750 - val_loss: 0.3371 - val_acc: 0.8000\n",
      "Epoch 50/50\n",
      "3/3 [==============================] - 1s 279ms/step - loss: 0.3521 - acc: 0.8646 - val_loss: 0.0876 - val_acc: 1.0000\n",
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory('/home/dev2/Sanjana/Metadata Extraction/dataset/train',\n",
    "                                                 target_size=(64, 64),\n",
    "                                                 batch_size=32,\n",
    "                                                 class_mode='binary')\n",
    "\n",
    "test_set = test_datagen.flow_from_directory('/home/dev2/Sanjana/Metadata Extraction/dataset/test',\n",
    "                                            target_size=(64, 64),\n",
    "                                            batch_size=32,\n",
    "                                            class_mode='binary')\n",
    "\n",
    "classifier.fit_generator(training_set,\n",
    "                        samples_per_epoch=100,\n",
    "                        nb_epoch=50,\n",
    "                        validation_data=test_set,\n",
    "                        nb_val_samples=200)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Saving the model\n",
    "model_json = classifier.to_json()\n",
    "with open(\"/home/dev2/Sanjana/Metadata Extraction/models/model.json\", \"w\") as json_file :\n",
    "    json_file.write(model_json)\n",
    "\n",
    "classifier.save_weights(\"/home/dev2/Sanjana/Metadata Extraction/models/model.h5\")\n",
    "print(\"Saved model to disk\")\n",
    "\n",
    "classifier.save('/home/dev2/Sanjana/Metadata Extraction/models/CNN.model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Part 3 - Making new predictions\n",
    "\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "import docx2txt\n",
    "import glob, os, shutil\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "docxnope=[]\n",
    "legalok=[]\n",
    "doc_name=[]\n",
    "\n",
    "classifier = tf.keras.models.load_model(\"/home/dev2/Sanjana/Metadata Extraction/models/CNN.model\")\n",
    "\n",
    "path=r'/home/dev2/1tb/SANJANA/Word/'\n",
    "os.chdir(r'/home/dev2/1tb/SANJANA/Word/')\n",
    "for file in glob.glob(\"*.docx\"):\n",
    "    doc_name.append(file)\n",
    "    dir_name=file.replace('.docx','')\n",
    "    try:\n",
    "        #print(\"errorpoint1\")\n",
    "        os.makedirs(path+dir_name)\n",
    "        #print(\"dir made\",dir_name)\n",
    "        img_dir=path+'/'+dir_name\n",
    "        nope_dir=img_dir+'/'+dir_name\n",
    "        os.makedirs(nope_dir)\n",
    "        text = docx2txt.process(path+file, img_dir) \n",
    "        data_path = os.path.join(img_dir,'*.png')\n",
    "        files = glob.glob(data_path)\n",
    "        #print(\"errorpoint2\")\n",
    "        data = []\n",
    "        for f1,imgid in zip(files,range(1,len(files))):\n",
    "            a=f1.replace('.png',\"\")\n",
    "            #print(dir_name)\n",
    "            the_img=a+'__'+dir_name+'.png'\n",
    "            #print(the_img)\n",
    "            if os.path.isfile(f1):\n",
    "                os.rename(f1,the_img)\n",
    "                shutil.copy(the_img,r'/home/dev2/1tb/SANJANA/all_images') \n",
    "    except:\n",
    "        print(\"error in doc name\",file)\n",
    "        \n",
    "#         test_image = image.load_img(f1, target_size=(64, 64))\n",
    "#         test_image = image.img_to_array(test_image)\n",
    "#         test_image = np.expand_dims(test_image, axis = 0)\n",
    "#         result = classifier.predict(test_image)\n",
    "#         if result[0][0] == 1: \n",
    "#             #print(\"legalok\")\n",
    "#             data.append('legalok')\n",
    "#             docxnope.append(f1)\n",
    "\n",
    "#         else:\n",
    "#             #print(\"nope\")\n",
    "#             data.append('nope')\n",
    "#     except:\n",
    "#         print(\"someerror\")\n",
    "#         pass\n",
    "#     for i in docxnope:\n",
    "#         if os.path.isfile(i):\n",
    "#             shutil.copy(i, nope_dir)\n",
    "#         else:\n",
    "#             print (\"file does not exist\", i)\n",
    "#             print(i)    \n",
    "#     if \"legalok\" in data:\n",
    "#         indices = [i for i, x in enumerate(data) if x == \"legalok\"]\n",
    "#         #print(file,\"yo present! at path\",indices)\n",
    "#         legalok.append(\"yes\")\n",
    "#     else:\n",
    "#         #print(file,\"not present\")\n",
    "#         legalok.append(\"no\")\n",
    "\n",
    "# import pandas as pd\n",
    "# df=pd.read_excel(r'/home/dev2/Sanjana/legalok_1stcut.xlsx')\n",
    "# df['Document_Name']= doc_name\n",
    "# df['legal ok']=legalok\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_excel(r\"/home/dev2/Sanjana/Stamp/trainingagain.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fi\n"
     ]
    }
   ],
   "source": [
    "print(\"fi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ERRORDOCS']=docxnope\n",
    "\n",
    "df.to_excel(r\"/home/dev2/Sanjana/Stamp/trainingagain.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, os, shutil\n",
    "for i in docxnope:\n",
    "    print(docxnope)\n",
    "    if os.path.isfile(i):\n",
    "        print(\"yes\")\n",
    "        shutil.copy(i, nope_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,5):\n",
    "    print(type(str(i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "import docx2txt\n",
    "import glob, os, shutil\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import os,glob\n",
    "data_path = os.path.join(r'/home/dev2/1tb/SANJANA/Word','*.png')\n",
    "files = glob.glob(data_path)\n",
    "data=[]\n",
    "docxnope=[]\n",
    "print(len(files))\n",
    "for f1 in files:\n",
    "    test_image = image.load_img(f1, target_size=(64, 64))\n",
    "    test_image = image.img_to_array(test_image)\n",
    "    test_image = np.expand_dims(test_image, axis = 0)\n",
    "    result = classifier.predict(test_image)\n",
    "    print(result)\n",
    "    if result[0][0] == 1: \n",
    "        #print(\"legalok\")\n",
    "        data.append('legalok')\n",
    "        docxnope.append(f1)\n",
    "        if os.path.isfile(f1):\n",
    "            shutil.copy(f1, r'/home/dev2/1tb/SANJANA/all_images')                \n",
    "\n",
    "    else:\n",
    "        pass\n",
    "        #print(\"nope\")\n",
    "        #data.append('nope')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(r'/home/dev2/Sanjana/legalok_1stcut.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
